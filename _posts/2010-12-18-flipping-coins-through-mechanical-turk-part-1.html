---
permalink: /flipping-coins-through-mechanical-turk-part-1/index.html
layout: post
title: ! 'Flipping Coins through Mechanical Turk: Part 1'
published: true
date: 2010-12-18 18:42:00
tags:
- ! ' mturk'
- behavioral econ
- research
---
<p><em>Over the past semester, I participated in an Independent Study in Behavioral Economics with Professor Jason Dana.&nbsp; Here's what we've been up to</em>:</p>
<p><strong>Mechanical Tur</strong><strong>k </strong>is Amazon's 'artificial artificial intelligence' service.<img loading="eager" class="img-fluid" width="100%" src="/images/250px-Kempelen_chess1.jpg" alt="Flipping Coins through Mechanical Turk: Part 1" /> Named after a <a href="http://en.wikipedia.org/wiki/The_Turk">fake chess-playing machine</a> in the late 17th-18th century, According to Amazon, MTurk is a</p>
<blockquote>
<p><span style="font-size: small;">marketplace for work that requires human intelligence. The Mechanical Turk web service enables companies to programmatically access this marketplace and a diverse, on-demand workforce. Developers can leverage this service to build human intelligence directly into their appli</span><em></em><span style="font-size: small;">cations</span></p>
</blockquote>
<p>As <a href="http://www.codinghorror.com/blog/2007/04/is-amazons-mechanical-turk-a-failure.html">Jeff Atwood explains</a>,</p>
<blockquote>
<p><span style="font-size: small;">It's a service that attempts to match people to small, bite-size units of work that are unsuitable for machines.</span></p>
</blockquote>
<p>For example: You have a list of thousands websites and want to know which ones are appear to be well-designed. Algorithms to quantify taste do not yet (sadly) exist; instead, either look through the websites yourself, or offer the task to Mechanical Turk. Turkers, as the workers are called, are then paid 5 cents (or however much you offer) to rate each website. Hundreds of people can work on your classification task in parralel, saving time and money.<em></em></p>
<p>Common uses of Mechanical Turk include transcribing audio, identifying photos, or answering opinion surveys.</p>
<p><strong>The Cheating Problem</strong></p>
<p>Without oversight, what prevents Turkers from voting randomly? For objective tasks, you could manually go over each result yourself, but this would be exteremely time-intensive and defeat the purpose. For subjective tasks, even that wouldn't be possible - who knows if the Turker's choice of 3/10 for some website was<em></em> his actual opinion or a random choice?</p>
<p>There are a couple of approaches that work here. You could try to get multiple Turkers to do each task and make sure they agree on the answers.&nbsp; You could do part of the work yourself, (set a <strong>gold standard</strong>) and verify Turker quality by how well they do on the tasks to which you now know the right answers. Finally, you can restrict your Turker employee base to a highly-qualified one, limiting your employee pool to those who have done good work before.&nbsp; As a side note, companies like <a href="http://crowdflower.com/">CrowdFlower</a> try to restrict and manage for high-quality workers on your behalf; if you're willing to pay more for your automated tasks, I've heard good things about them.</p>
<p>Amazon measures this 'done good work before' metric by looking at the Turker's <strong>HIT Approval Rate - </strong>the % of tasks that this worker has done in the past that were subsequently accepted by the employer. Limiting your workers to 95%+ is a standard way of trying to obtain only high-quality responses.</p>
<p><strong>The Research Question</strong></p>
<p>The question, then, is whether limiting the Turkers to those with a high acceptance rate is an effective way of making sure they don't cheat.&nbsp; We were also wondering where the cutoff for cheaters was and whether the amount of money offered for the task would affect the amount of cheating.<em></em></p>
<p><strong>The Setup<br /></strong></p>
<p>Our experiment is as simple as possible:<em><span style="font-style: normal;"><em></em></span><img loading="eager" class="img-fluid" width="100%" src="/images/flipacoin.png" alt="Flipping Coins through Mechanical Turk: Part 1" /></em><em></em></p>
<p>The idea is based on an experiment Prof. Dana has run at Solomon Behavioral Labs at Penn as well as abroad [that we should probably link to/cite here].&nbsp; We can't tell if any particular individual is cheating - perhaps they happened to flip heads - but in the aggregate, if we ask 50 homogenous Turkers to flip a coin and see how many heads we get, 50 heads indicates that the Turkers are a dishonest bunch, while 25 heads and 25 tails would indicate a fair and friendly group of turkers.</p>
<p>We offered the same task to 50 turkers in one of several groups, varying by <strong>HIT Approval Rate. </strong><span style="font-family: mceinline;">An informal survey (IE, we asked one of Prof. Dana's grad students)</span> suggested that cutoffs of &lt;89%, 90-94%, 95-97%, 98-99% and 100% would be reasonable. We also offered the task to a group of Turk newbies (filtered by the fact that they had less than 20 tasks completed under their belt).</p>
<p>Offering 2c for tails and 4c for heads, we hoped to see how rampant cheating for subjective tasks was amongst various groups of accom<em></em>plishment.&nbsp;</p>
<p><strong><a name="results">The Results</a></strong><em><img loading="eager" class="img-fluid" width="100%" src="/images/results_2c4c.PNG" alt="Flipping Coins through Mechanical Turk: Part 1" /></em>The data did not dissapoint. Excluding the 95-97% anomaly, the trend was clear: the better your Turkers, the more honest (by and large) they would be when offered subjective tasks where they could cheat without being detected.</p>
<p>Since this was our first attempt at Mechanical Turk, though, we did not do as good of a job with the price offered or the marketing of the task (we named it 'Project Random'). As a result, we got only 158 participants (out of a possible 300), and only 19 100%-ers.&nbsp; Clearly, the price offered would have to go up.&nbsp;</p>
<p>How do you think offering more money affected the cheating chart? Should cheating go up or down, as a whole, if we offer 5c/10c instead of 2c/4c? Should any groups be more or less affected than average by an increased incentive to cheat?</p>
<p><em>Update: Part 2 is available <a href="/flipping-coins-through-mechanical-turk-part-2">here</a>.</em></p>
